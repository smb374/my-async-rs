<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Design and Implementation Detail of my-async</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="intro.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Prerequisite Knowledges</li><li class="chapter-item expanded "><a href="pre/async_in_rust.html"><strong aria-hidden="true">1.</strong> Async in Rust</a></li><li class="chapter-item expanded "><a href="pre/overview.html"><strong aria-hidden="true">2.</strong> Overview of an executor's architechture</a></li><li class="chapter-item expanded "><a href="pre/single_thread_executor.html"><strong aria-hidden="true">3.</strong> A minimal single-threded Future evaluator</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="pre/single_future_handle.html"><strong aria-hidden="true">3.1.</strong> Future handling</a></li><li class="chapter-item expanded "><a href="pre/single_global_storage.html"><strong aria-hidden="true">3.2.</strong> Global Storages</a></li><li class="chapter-item expanded "><a href="pre/single_message_passing.html"><strong aria-hidden="true">3.3.</strong> Message Passing</a></li><li class="chapter-item expanded "><a href="pre/single_executor.html"><strong aria-hidden="true">3.4.</strong> Executor Main Loop</a></li><li class="chapter-item expanded "><a href="pre/single_final_code.html"><strong aria-hidden="true">3.5.</strong> Final Code</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">First layer - Future and IoWrapper</li><li class="chapter-item expanded "><a href="layer/fst/future_trait.html"><strong aria-hidden="true">4.</strong> Bone of async - Future trait</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/fst/future_in_depth.html"><strong aria-hidden="true">4.1.</strong> Future in depth</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/fst/mechanism.html"><strong aria-hidden="true">4.1.1.</strong> Future trait mechanism</a></li><li class="chapter-item expanded "><a href="layer/fst/fsm.html"><strong aria-hidden="true">4.1.2.</strong> Future desugar - a Finite State Machine</a></li><li class="chapter-item expanded "><a href="layer/fst/challenge.html"><strong aria-hidden="true">4.1.3.</strong> The challenge of managing Future objects</a></li></ol></li><li class="chapter-item expanded "><a href="layer/fst/handling.html"><strong aria-hidden="true">4.2.</strong> Generic Future handling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/fst/heap_alloc.html"><strong aria-hidden="true">4.2.1.</strong> General heap-allocated Future object</a></li><li class="chapter-item expanded "><a href="layer/fst/pool.html"><strong aria-hidden="true">4.2.2.</strong> Global Reusable Object Pool for allocation reuse, fragment control, and easy managment</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="layer/fst/io_wrapper.html"><strong aria-hidden="true">5.</strong> IO Adapter for general file descriptor - IoWrapper</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/fst/io_handling.html"><strong aria-hidden="true">5.1.</strong> General IO handling</a></li><li class="chapter-item expanded "><a href="layer/fst/io_wrapper_design.html"><strong aria-hidden="true">5.2.</strong> IoWrapper design</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Second layer - Executor and message passing</li><li class="chapter-item expanded "><a href="layer/snd/executor.html"><strong aria-hidden="true">6.</strong> Heart of a runtime - Executor</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/snd/commands.html"><strong aria-hidden="true">6.1.</strong> General commands of a runtime</a></li><li class="chapter-item expanded "><a href="layer/snd/message_handling.html"><strong aria-hidden="true">6.2.</strong> Design of Executor</a></li></ol></li><li class="chapter-item expanded "><a href="layer/snd/message_passing.html"><strong aria-hidden="true">7.</strong> Passing messages</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/snd/spawner.html"><strong aria-hidden="true">7.1.</strong> Spawner - a message sender</a></li><li class="chapter-item expanded "><a href="layer/snd/message_payload.html"><strong aria-hidden="true">7.2.</strong> Message payload</a></li></ol></li><li class="chapter-item expanded "><a href="layer/snd/join_handle.html"><strong aria-hidden="true">8.</strong> Join Handle for Future</a></li><li class="chapter-item expanded affix "><li class="part-title">Third layer - Scheduler and schedule problems</li><li class="chapter-item expanded "><a href="layer/trd/scheduler.html"><strong aria-hidden="true">9.</strong> Multithread mania - Scheduler</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/trd/scheduler_trait.html"><strong aria-hidden="true">9.1.</strong> Scheduler trait design</a></li><li class="chapter-item expanded "><a href="layer/trd/worker_structure.html"><strong aria-hidden="true">9.2.</strong> General Worker structure and logic</a></li><li class="chapter-item expanded "><a href="layer/trd/schedule_procedure.html"><strong aria-hidden="true">9.3.</strong> The procedure of task scheduling</a></li></ol></li><li class="chapter-item expanded "><a href="layer/trd/threading_method.html"><strong aria-hidden="true">10.</strong> Threading Method</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/trd/round_robin.html"><strong aria-hidden="true">10.1.</strong> Round Robin</a></li><li class="chapter-item expanded "><a href="layer/trd/work_stealing.html"><strong aria-hidden="true">10.2.</strong> Work Stealing</a></li><li class="chapter-item expanded "><a href="layer/trd/hybrid.html"><strong aria-hidden="true">10.3.</strong> Hybrid Queue for Prioritized Work Stealing</a></li></ol></li><li class="chapter-item expanded "><a href="layer/trd/token_bucket.html"><strong aria-hidden="true">11.</strong> A token bucket like algorithm for auto task yielding</a></li><li class="chapter-item expanded affix "><li class="part-title">Fourth layer - Reactor and Waker handling</li><li class="chapter-item expanded "><a href="layer/fth/reactor.html"><strong aria-hidden="true">12.</strong> System IO Event Harvester - Reactor</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/fth/io_registration.html"><strong aria-hidden="true">12.1.</strong> IO event registeration</a></li><li class="chapter-item expanded "><a href="layer/fth/event_handling.html"><strong aria-hidden="true">12.2.</strong> Event handling</a></li><li class="chapter-item expanded "><a href="layer/fth/event_maintain.html"><strong aria-hidden="true">12.3.</strong> Event maintain for late use</a></li></ol></li><li class="chapter-item expanded "><a href="layer/fth/waker_handling.html"><strong aria-hidden="true">13.</strong> Waker handling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="layer/fth/global_map.html"><strong aria-hidden="true">13.1.</strong> Global slab for wakers</a></li><li class="chapter-item expanded "><a href="layer/fth/registration.html"><strong aria-hidden="true">13.2.</strong> Waker registration</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Unresolved Problems and Future Works</li><li class="chapter-item expanded "><a href="prob/load_balancing.html"><strong aria-hidden="true">14.</strong> Load Balancing</a></li><li class="chapter-item expanded "><a href="prob/generic_payload.html"><strong aria-hidden="true">15.</strong> Generic Message Payload</a></li><li class="chapter-item expanded "><a href="prob/reactor_abstract.html"><strong aria-hidden="true">16.</strong> Reactor abstraction for different systems</a></li><li class="chapter-item expanded affix "><li class="part-title">References</li><li class="chapter-item expanded "><a href="references.html"><strong aria-hidden="true">17.</strong> References</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Design and Implementation Detail of my-async</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>This book is about the design and the implementation of <code>my-async</code>, a Rust async IO runtime.
Why creating a new runtime instead of using <code>tokio</code>? The problem of <code>tokio</code> is that its codebase is
huge and hard to trace down, a least for me.</p>
<p>When I was trying to understand <code>tokio</code>'s approach to async,
there are more than 35000+ lines of code, it's just too much for a CS student like me.
So I decided to work on a new runtime with a clear documentation
over the design and implementation as my graduate project.</p>
<p><code>my-async</code> has the following goals:</p>
<ul>
<li>A convenient interface to wrap over <code>AsFd</code> types.</li>
<li>A <code>Scheduler</code> trait that makes applying new scheduling strategy easy.</li>
<li>A relatively short code that is easy to read.</li>
<li>Having a decent performance compare to <code>tokio</code>.</li>
<li>Clear documentation that can express its design and implementation.</li>
</ul>
<p>Without a doubt, let's get started.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="async-in-rust"><a class="header" href="#async-in-rust">Async in Rust</a></h1>
<p>Async in Rust is simple and complex at the same time. If you're the user, you can simply do
the following stuff as an async 101:</p>
<pre><code class="language-rust">#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    println!(&quot;Hello async!&quot;);
    let result = async_io_fn_one().await?;
    println(&quot;Get IO result: {}&quot;, result);
    Ok(())
}
</code></pre>
<p>Just that simple.</p>
<p>On the other hand, if you want to dig inside, thing can get quite tricky.</p>
<p>Async in Rust is kind of different from other languages: it doesn't have a standard runtime.
The decision is made by the core language team to:</p>
<ol>
<li>Maintain fexibility over implementations that is suitable to different scenarios</li>
<li>Keep the size of the standard library small.</li>
</ol>
<p>The result of the decision is the <code>Future</code> trait. Anything that implements <code>Future</code> can
use the <code>.await</code> keyword to execute it asynchronously. The compiler can also implement
<code>Future</code> for normal function by adding <code>async</code> before the <code>fn</code> keyword.</p>
<p>The approach however, cause a problem: by the design of the <code>Future</code> trait, it is lazy.
<code>Future</code> won't make any progress to the underlying code until someone use <code>poll()</code> method
to poll it. In other words, <code>Future</code> needs to be polled by some mechanism to work.
There are multiple ways to poll a <code>Future</code> object, most commonly by an executor.</p>
<p>The executor needs to be capable to dispatch, manage, and execute <code>Future</code>. The implementation
of an executor can look very different, depending on the context, resources, and platform.
Generally an executor can be divided to a few parts and will later be discussed in the next part.</p>
<p>There are numbers of executor implementations in exist, such as <code>tokio</code>, <code>async-std</code>, <code>smol</code>, etc.
The problem is that they are not compactible, since executor need to store numerous of states to help
executing the <code>Future</code> objects. The problem is still unsolved until now and hopefully can be solved one day.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-of-an-executors-architechture"><a class="header" href="#overview-of-an-executors-architechture">Overview of an executor's architechture</a></h1>
<p>The diagram of the executor's architechture:
<img src="https://i2.lensdump.com/i/RR65QP.png" alt="Executor Layer" /></p>
<p>By the above diagram, we can divide the executor into 4 layers:</p>
<h2 id="first-layer---future-and-iowrapper"><a class="header" href="#first-layer---future-and-iowrapper">First Layer - Future and IoWrapper</a></h2>
<p>The job of this layer is provide user interaction with the executor in a convenient way.
A global spawner is provided to send command to the executor to spawn an async function or to shutdown the executor.
The spawned function will return a join handle to join and retrieve the return value of that function.</p>
<p><code>IoWrapper</code> is provided for convenient <code>AsFd</code> type wrapping. It also provides <code>ref_io</code> and <code>mut_io</code> for those
IO actions that is not predefined to run as async.</p>
<h2 id="second-layer---executor"><a class="header" href="#second-layer---executor">Second layer - Executor</a></h2>
<p>This is the surface of the executor. The main job of this layer is to handle message from the spawner and command
the underlying scheduler and reactor by corresponding message.</p>
<p>The executor itself will also set up the global spawner, scheduler with all the worker threads, and the reactor thread
on init for the runtime to work. After the executor is initialized, the user is required to <code>block_on</code> a single main
async function to fire up the runtime.</p>
<h2 id="third-layer---scheduler"><a class="header" href="#third-layer---scheduler">Third layer - Scheduler</a></h2>
<p>This layer will adapt the defined scheduling strategy to schedule async tasks to the workers.
The provided <code>Scheduler</code> trait is an abstract layer that defines a scheduler's basic behavior for executor to use.
This is crutial for new scheduling strategy to be able to plug into this runtime easily.</p>
<p>Currently, <code>RoundRobinScheduler</code>, <code>WorkStealingScheduler</code>, and <code>HybridScheduler</code> is implemented by default.</p>
<h2 id="fourth-layer---reactor-and-waker-handling"><a class="header" href="#fourth-layer---reactor-and-waker-handling">Fourth layer - Reactor and Waker Handling</a></h2>
<p>This layer will communicate with the system and harvest all IO events repoted. Once the IO events are harvested,
the reactor will:</p>
<ol>
<li>If there are wakers registed related to a event, wake it up.</li>
<li>If not, store it to a table for later usage.</li>
</ol>
<p>Since the underlying call is handled by <code>mio</code> that is edge-triggered, we need to check the stored events
with currently registered wakers to make sure every event is consumed.</p>
<p>The datails of the layer will be discussed later in the following chapters, but first, I will give an implementation
of a single-threaded executor to help you understand the main idea of an executor, then we'll move on to the multi-threaded version.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="a-minimal-single-threded-future-evaluator"><a class="header" href="#a-minimal-single-threded-future-evaluator">A minimal single-threded Future evaluator</a></h1>
<p>This section will give an simple single-threaded executor implementation
for you to understand the whole picture of the following chapters, as</p>
<ol>
<li>It doesnt't require a scheduler and any synchronisation.</li>
<li>The reacter is a relatively small factor to express the idea, we'll talk about it later.</li>
</ol>
<p>If you want to see the reactor's part first, see <a href="pre/../layer/fth/reactor.html">System IO Event Harvester - Reactor</a>
and the following subsections.</p>
<p>Now, let's get started from <code>Future</code> handling.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="future-handling"><a class="header" href="#future-handling">Future handling</a></h1>
<p>Since the compiler will generate any <code>async fn</code> functions as <code>Future</code> objects,
the generic type will be a hurdle to program, allocating these <code>Future</code> objects
as boxed trait objects is more sensable and easier to program.</p>
<p>First we define a <code>BoxedLocal&lt;T&gt;</code> type alias and <code>BoxedFuture</code> type:</p>
<pre><code class="language-rust  noplaypen">type BoxedLocal&lt;T&gt; = Pin&lt;Box&lt;dyn Future&lt;Output = T&gt; + 'static&gt;&gt;;

struct BoxedFuture {
    future: RefCell&lt;Option&lt;BoxedLocal&lt;io::Result&lt;()&gt;&gt;&gt;&gt;,
}
</code></pre>
<p>Here we use <code>RefCell</code> for internal mutability and we assumed that all
enclosed should return <code>std::io::Result&lt;()&gt;</code> as <code>Future</code> requires to mutate it self
by its trait definition and most of the tasks are IO bounded to be used under async environments.</p>
<p>To handle the underlying <code>async fn</code>, we define the <code>run</code> function as the following:</p>
<pre><code class="language-rust">impl BoxedFuture {
    fn run(&amp;self, index: &amp;FutureIndex, tx: Sender&lt;FutureIndex&gt;) -&gt; bool {
        let mut guard = self.future.borrow_mut();
        // run *ONCE*
        if let Some(fut) = guard.as_mut() {
            let new_index = FutureIndex {
                key: index.key,
            };
            // Create a waker that sends back the future to the process queue
            // once it's woke by that reactor.
            let waker = waker_fn(move || {
                tx.send(new_index).expect(&quot;Too many message queued!&quot;);
            });
            // Create a Context from the waker we just created.
            let cx = &amp;mut Context::from_waker(&amp;waker);
            // Poll the underlying future with cx
            match fut.as_mut().poll(cx) {
                Poll::Ready(r) =&gt; {
                    if let Err(e) = r {
                        // log error to logging facility
                        log::error!(&quot;Error occurred when executing future: {}&quot;, e);
                    }
                    true // Return value ready
                }
                Poll::Pending =&gt; false, // Pending
            }
        } else {
            true // Finished already
        }
    }
}
</code></pre>
<p>The process goes by:</p>
<ol>
<li>Check if it's done already for handling spurious call.</li>
<li>Create a waker that sends the index of itself back to process queue.</li>
<li>Create a <code>Context</code> for future polling using the waker we've just created.</li>
<li>Poll the future and match the result.</li>
</ol>
<p>Next, we'll talk about the global storage.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="global-storages"><a class="header" href="#global-storages">Global Storages</a></h1>
<p>By the design from me, every future should store in a global allocation pool for
allocation reuse and easy management. The details will be discussed in the
<a href="pre/../layer/fst/pool.html">Global Reusable Object Pool for fragment controll and Future managment</a>
part.</p>
<p>We first define <code>FUTURE_POOL</code> and <code>SPAWNER</code> as thread local objects as Rust assumes
you are under multi-threaded environment without specific instruction. This will
cause some bounds for global variables to guarentee memory safety.</p>
<pre><code class="language-rust">thread_local! {
    static SPAWNER: RefCell&lt;Option&lt;Spawner&gt;&gt; = RefCell::new(None);
    static FUTURE_POOL: Pool&lt;BoxedFuture&gt; = Pool::new();
}
</code></pre>
<p>Since <code>Pool</code> is already lock-free, we don't need to use <code>RefCell</code> to encapsulate it.
The <code>SPAWNER</code> is used as an message sender and will be discuss in the next section.</p>
<p>We also need to define a <code>FutureIndex</code> that contains the key returned by the <code>Pool</code> and other
payloads(Though there are no other payloads in this case):</p>
<pre><code class="language-rust">#[derive(Clone, Copy, Eq)]
struct FutureIndex {
    key: usize,
}

impl PartialEq for FutureIndex {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        self.key == other.key
    }
}

impl Hash for FutureIndex {
    fn hash&lt;H: std::hash::Hasher&gt;(&amp;self, state: &amp;mut H) {
        self.key.hash(state);
    }
}
</code></pre>
<p>and implement <code>Clear</code> for the <code>BoxedFuture</code> for the allocation reserve part:</p>
<pre><code class="language-rust">impl Clear for BoxedFuture {
    fn clear(&amp;mut self) {
        self.future.borrow_mut().clear();
    }
}
</code></pre>
<p>Next, we'll move on to the message passing part.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="message-passing"><a class="header" href="#message-passing">Message Passing</a></h1>
<p>The <code>SPAWNER</code> we defined in the last part is used as a global message sender,
the underlying type is defined as:</p>
<pre><code class="language-rust">struct Spawner {
    tx: Sender&lt;Message&gt;,
}

enum Message {
    Run(FutureIndex),
    Close,
}
</code></pre>
<p>while the receiver half is held by tthe executor.
The are two messages: <code>Run</code> and <code>Close</code>:</p>
<ul>
<li><code>Run</code> is used to put the spawned future into the process queue.</li>
<li><code>Close</code> is used to signal the executor to shutdown.</li>
</ul>
<p>With the messages defined, we need to implement the corresponding functions:</p>
<pre><code class="language-rust">impl Spawner {
    fn spawn&lt;F&gt;(&amp;self, future: F)
    where
        F: Future&lt;Output = io::Result&lt;()&gt;&gt; + 'static,
    {
        // Alloc future inside the pool and retrieve its key to the entry.
        let key = FUTURE_POOL.with(|p| {
            p.create_with(|seat| {
                seat.future.borrow_mut().replace(Box::pin(future));
            })
            .unwrap()
        });
        // Send run command to the executor.
        self.tx
            .send(Message::Run(FutureIndex {
                key,
            }))
            .expect(&quot;too many task queued&quot;);
    }
    fn shutdown(&amp;self) {
        // Send shutdown command to the executor.
        self.tx.send(Message::Close).expect(&quot;too many task queued&quot;);
    }
}

// Corresponding public function for global spawner access.

pub fn spawn&lt;F&gt;(fut: F)
where
    F: Future&lt;Output = io::Result&lt;()&gt;&gt; + 'static,
{
    SPAWNER.with(|s| {
        if let Some(spawner) = s.borrow().as_ref() {
            spawner.spawn(fut);
        }
    })
}

pub fn shutdown() {
    SPAWNER.with(|s| {
        if let Some(spawner) = s.borrow().as_ref() {
            spawner.shutdown();
        }
    })
}
</code></pre>
<p>Note that the join handle is not implemented in this single-threaded executor for simplicity.
For the join handle implementation, please look <a href="pre/../layer/snd/join_handle.html">Join Handle for Future</a>.</p>
<p>Finally, we come to the main loop that handles the message.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="executor-main-loop"><a class="header" href="#executor-main-loop">Executor Main Loop</a></h1>
<p>Inside the main loop, there are a few stages:</p>
<ol>
<li>Pop and make a certain of progress of all futures in the waiting queue.</li>
<li>Try to receive to receive as much as futures that is waken up by the reactor.</li>
<li>Try to receive any message from the spawner.</li>
<li>Finally, wait for reactor to harvest events.</li>
</ol>
<h2 id="stage-1"><a class="header" href="#stage-1">Stage 1</a></h2>
<pre><code class="language-rust">let mut reactor = reactor::Reactor::default();
reactor.setup_registry();
'outer: loop {
    if let Some(index) = self.queue.pop_back() {
        FUTURE_POOL.with(|p| {
            if let Some(boxed) = p.get(index.key) {
                let finished = boxed.run(&amp;index, self.task_tx.clone());
                if finished &amp;&amp; !p.clear(index.key) {
                    log::error!(
                        &quot;Failed to remove completed future with index = {} from pool.&quot;,
                        index.key
                    );
                }
            } else {
                log::error!(&quot;Future with index = {} is not in pool.&quot;, index.key);
            }
        });
    } else {
      // Other stages
    }
}
</code></pre>
<p>Here we first setup the reactor for later use, and start popping <code>FutureIndex</code>s from
waiting queue. The error handling here is simply log the errors to the logging facility
for maintaining a short code. The process can be addressed as:</p>
<ol>
<li>Retrieve the <code>BoxedFuture</code> by the key of <code>FutureIndex</code>.</li>
<li>Use <code>BoxedFuture::run()</code> to make progress with the return value indicating id it's finished.</li>
<li>If it's finished, delete it from the global storage.</li>
</ol>
<h2 id="stage-2"><a class="header" href="#stage-2">Stage 2</a></h2>
<pre><code class="language-rust">'outer: loop {
    if let Some(index) = self.queue.pop_back() {
        // Stage 1
    } else {
        let mut wakeup_count = 0;
        loop {
            match self.task_rx.try_recv() {
                Ok(index) =&gt; {
                    wakeup_count += 1;
                    self.queue.push_front(index);
                }
                Err(TryRecvError::Empty) =&gt; break,
                Err(TryRecvError::Disconnected) =&gt; break 'outer,
            }
        }
        if wakeup_count &gt; 0 {
            continue;
        }
        // Other stages
    }
}
</code></pre>
<p>Here we use a counter to record the number of woke up futures. If there is any,
process those future first. The receive is non-blocking, so two possible error
will need to be handle:</p>
<ol>
<li><code>TryRecvError::Empty</code>: The channel is empty, stop trying to receive.</li>
<li><code>TryRecvError::Disconnected</code>: All the producer are disconnected, which means all futures are done, exit main loop directly.</li>
</ol>
<h2 id="stage-3-and-stage-4"><a class="header" href="#stage-3-and-stage-4">Stage 3 and Stage 4</a></h2>
<pre><code class="language-rust">'outer: loop {
    if let Some(index) = self.queue.pop_back() {
        // Stage 1
    } else {
        // Stage 2
        match self.rx.try_recv() {
            Ok(Message::Run(index)) =&gt; {
                self.queue.push_front(index);
            }
            Err(TryRecvError::Empty) =&gt; {
                if let Err(e) = reactor.wait(Some(Duration::from_millis(50))) {
                    log::error!(&quot;reactor wait error: {}, exit&quot;, e);
                    break;
                }
            }
            Ok(Message::Close) | Err(TryRecvError::Disconnected) =&gt; break,
        }
    }
}
</code></pre>
<p>These are the last stage in the main loop. Here the runtime will wait for any schedule messages
send by the global spawner, whether to run a new future or shutdown the runtime.
If there are no messages from the global spwaner, we start to wait for reactor to wake up some futures.</p>
<p>Note that we need to check messages from global spawner at the same time, so we can't use indefinite
waiting on reactor. A time period need to be chosen to block the loop for a decent small amount of time
without spuriously wake up the main thread too frequently.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="final-code"><a class="header" href="#final-code">Final Code</a></h1>
<p>The final code is shown as below:</p>
<pre><code class="language-rust">use super::reactor;

use std::{
    cell::RefCell,
    collections::VecDeque,
    future::Future,
    hash::Hash,
    io,
    pin::Pin,
    rc::Rc,
    task::{Context, Poll},
    time::Duration,
};

use flume::{Receiver, Sender, TryRecvError};
use sharded_slab::{Clear, Pool};
use waker_fn::waker_fn;

thread_local! {
    static SPAWNER: RefCell&lt;Option&lt;Spawner&gt;&gt; = RefCell::new(None);
    static FUTURE_POOL: Pool&lt;BoxedFuture&gt; = Pool::new();
}

type BoxedLocal&lt;T&gt; = Pin&lt;Box&lt;dyn Future&lt;Output = T&gt; + 'static&gt;&gt;;

#[derive(Clone, Copy, Eq)]
struct FutureIndex {
    key: usize,
}

impl PartialEq for FutureIndex {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        self.key == other.key
    }
}

impl Hash for FutureIndex {
    fn hash&lt;H: std::hash::Hasher&gt;(&amp;self, state: &amp;mut H) {
        self.key.hash(state);
    }
}

struct BoxedFuture {
    future: RefCell&lt;Option&lt;BoxedLocal&lt;io::Result&lt;()&gt;&gt;&gt;&gt;,
}

impl Default for BoxedFuture {
    fn default() -&gt; Self {
        BoxedFuture {
            future: RefCell::new(None),
        }
    }
}

impl Clear for BoxedFuture {
    fn clear(&amp;mut self) {
        self.future.borrow_mut().clear();
    }
}

impl BoxedFuture {
    fn run(&amp;self, index: &amp;FutureIndex, tx: Sender&lt;FutureIndex&gt;) -&gt; bool {
        let mut guard = self.future.borrow_mut();
        // run *ONCE*
        if let Some(fut) = guard.as_mut() {
            let new_index = FutureIndex {
                key: index.key,
            };
            let waker = waker_fn(move || {
                tx.send(new_index).expect(&quot;Too many message queued!&quot;);
            });
            let cx = &amp;mut Context::from_waker(&amp;waker);
            match fut.as_mut().poll(cx) {
                Poll::Ready(r) =&gt; {
                    if let Err(e) = r {
                        log::error!(&quot;Error occurred when executing future: {}&quot;, e);
                    }
                    true
                }
                Poll::Pending =&gt; false,
            }
        } else {
            true
        }
    }
}

enum Message {
    Run(FutureIndex),
    Close,
}

pub struct Executor {
    task_tx: Sender&lt;FutureIndex&gt;,
    task_rx: Receiver&lt;FutureIndex&gt;,
    queue: VecDeque&lt;FutureIndex&gt;,
    rx: Receiver&lt;Message&gt;,
}

struct Spawner {
    tx: Sender&lt;Message&gt;,
}

impl Executor {
    pub fn new() -&gt; Self {
        let (tx, rx) = flume::unbounded();
        let (task_tx, task_rx) = flume::unbounded();
        let spawner = Spawner { tx };
        SPAWNER.with(|s| s.borrow_mut().replace(spawner));
        Self {
            task_tx,
            task_rx,
            queue: VecDeque::with_capacity(1024),
            rx,
        }
    }

    fn run(&amp;mut self) {
        let mut reactor = reactor::Reactor::default();
        reactor.setup_registry();
        'outer: loop {
            if let Some(index) = self.queue.pop_back() {
                FUTURE_POOL.with(|p| {
                    if let Some(boxed) = p.get(index.key) {
                        let finished = boxed.run(&amp;index, self.task_tx.clone());
                        if finished &amp;&amp; !p.clear(index.key) {
                            log::error!(
                                &quot;Failed to remove completed future with index = {} from pool.&quot;,
                                index.key
                            );
                        }
                    } else {
                        log::error!(&quot;Future with index = {} is not in pool.&quot;, index.key);
                    }
                });
            } else {
                let mut wakeup_count = 0;
                loop {
                    match self.task_rx.try_recv() {
                        Ok(index) =&gt; {
                            wakeup_count += 1;
                            self.queue.push_front(index);
                        }
                        Err(TryRecvError::Empty) =&gt; break,
                        Err(TryRecvError::Disconnected) =&gt; break 'outer,
                    }
                }
                if wakeup_count &gt; 0 {
                    continue;
                }
                match self.rx.try_recv() {
                    Ok(Message::Run(index)) =&gt; {
                        self.queue.push_front(index);
                    }
                    Err(TryRecvError::Empty) =&gt; {
                        if let Err(e) = reactor.wait(Some(Duration::from_millis(50))) {
                            log::error!(&quot;reactor wait error: {}, exit&quot;, e);
                            break;
                        }
                    }
                    Ok(Message::Close) | Err(TryRecvError::Disconnected) =&gt; break,
                }
            }
        }
    }
    pub fn block_on&lt;F&gt;(mut self, future: F) -&gt; F::Output
    where
        F: Future + 'static,
    {
        let result_arc: Rc&lt;RefCell&lt;Option&lt;F::Output&gt;&gt;&gt; = Rc::new(RefCell::new(None));
        let clone = Rc::clone(&amp;result_arc);
        spawn(async move {
            let result = future.await;
            clone.borrow_mut().replace(result);
            log::debug!(&quot;Blocked future finished.&quot;);
            shutdown();
            Ok(())
        });
        log::info!(&quot;Start blocking...&quot;);
        self.run();
        log::debug!(&quot;Waiting result...&quot;);
        let mut guard = result_arc.borrow_mut();
        let result = guard.take();
        assert!(
            result.is_some(),
            &quot;The blocked future should produce a return value before the execution ends.&quot;
        );
        result.unwrap()
    }
}

impl Drop for Executor {
    fn drop(&amp;mut self) {
        SPAWNER.with(|s| {
            if let Some(spawner) = s.borrow().as_ref() {
                spawner
                    .tx
                    .send(Message::Close)
                    .expect(&quot;Message queue is full.&quot;);
            }
        });
    }
}

impl Default for Executor {
    fn default() -&gt; Self {
        Self::new()
    }
}

impl Spawner {
    fn spawn&lt;F&gt;(&amp;self, future: F)
    where
        F: Future&lt;Output = io::Result&lt;()&gt;&gt; + 'static,
    {
        let key = FUTURE_POOL.with(|p| {
            p.create_with(|seat| {
                seat.future.borrow_mut().replace(Box::pin(future));
            })
            .unwrap()
        });
        self.tx
            .send(Message::Run(FutureIndex { key }))
            .expect(&quot;too many task queued&quot;);
    }
    fn shutdown(&amp;self) {
        self.tx.send(Message::Close).expect(&quot;too many task queued&quot;);
    }
}

pub fn spawn&lt;F&gt;(fut: F)
where
    F: Future&lt;Output = io::Result&lt;()&gt;&gt; + 'static,
{
    SPAWNER.with(|s| {
        if let Some(spawner) = s.borrow().as_ref() {
            spawner.spawn(fut);
        }
    })
}

pub fn shutdown() {
    SPAWNER.with(|s| {
        if let Some(spawner) = s.borrow().as_ref() {
            spawner.shutdown();
        }
    })
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bone-of-async---future-trait"><a class="header" href="#bone-of-async---future-trait">Bone of async - Future trait</a></h1>
<p><code>Future</code> trait is the core of asynchronous IO in Rust.
Without it, the <code>async</code>/<code>await</code> keyword won't work, and
designer of a runtime will have to implement a callback
system to cooperate with the system IO event handle
loop.</p>
<p>In this section, we will take a deeper look into
the <code>Future</code> trait and talk about the technique I
use to handle it.</p>
<p>Without a second thought, let's dig in...</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="future-in-depth"><a class="header" href="#future-in-depth">Future in depth</a></h1>
<p>In this part, we will:</p>
<ul>
<li>Desugar the generated <code>Future</code> object from the <code>async fn</code> functions by the compiler.</li>
<li>Take a deeper look into <code>Future</code>'s trait definition and the <code>Waker</code> mechanism.</li>
<li>Discuss the challenge we will face under this mechanism.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="future-trait-mechanism"><a class="header" href="#future-trait-mechanism">Future trait mechanism</a></h1>
<p>The <code>Future</code> trait is defined as:</p>
<pre><code class="language-rust">pub trait Future {
    type Output;

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt;;
}
</code></pre>
<p>The trait defines:</p>
<ol>
<li><code>Output</code>: The execution result of the underlying <code>Future</code>.</li>
<li><code>poll</code>: The method that triggers the execution of a <code>Future</code> object. Returns <code>Poll</code> with two states:
<ul>
<li><code>Poll::Ready(Output)</code>: The <code>Future</code> successfully executes with its return value.</li>
<li><code>Poll::Pending</code>: The <code>Future</code> is currently pending, check it later to get the execution result.</li>
</ul>
</li>
</ol>
<p>By design, a <code>Future</code> object is lazy unless someone triggers the <code>poll</code> method defined
by the trait. The <code>poll</code> method contains a few unusual structs in it, including:</p>
<ol>
<li><code>Pin</code></li>
<li><code>Context</code></li>
</ol>
<p>We will look into these two struct in the following sections.</p>
<h2 id="1-the-pinp-smart-pointer"><a class="header" href="#1-the-pinp-smart-pointer">1. The <code>Pin&lt;P&gt;</code> smart pointer</a></h2>
<p>The <code>Pin&lt;P&gt;</code> smart pointer is a wrapper around the <code>P</code> pointer that ensures the pointee
will not move out of it's current address, i.e. the address that <code>P</code> points to. This effect is
canceled if the pointee type implements the <code>Unpin</code> auto trait.</p>
<p>For example, the <code>std::mem::swap</code> can swap the pointee of two pointers, which essentially &quot;moves&quot;
the pointee out of its original place. If we wrap the two pointers with <code>Pin</code>, the use of <code>swap</code>
is forbidden, the code will failed to compile.</p>
<p>The reason of the use of <code>Pin</code> is mostly for the self referral structures.
Consider the following structure:</p>
<pre><code class="language-rust">struct SelfRef {
    buf: [u8; 4096],
    p: &amp;[u8],
}
</code></pre>
<p>If the field <code>p</code> points to the field <code>buf</code>, when the whole struct is moved, the underlying fields will also be moved
while the pointer <code>p</code> is still pointing the location of <code>buf</code> before the move occurs. We can clearly see that
the following access <code>p</code> will cause undefined behavior since the pointee may be a different type or <code>p</code> becomes
a dangling pointer. With the use of <code>Pin</code>, we can avoid this kind of stuff and prevent undefined behavior.
These kind of type will also implements <code>!Unpin</code> to make <code>Pin</code> has its effect on the type.</p>
<p>The reason that <code>poll</code> requires this bound is related to the next section. For now, we will discuss <code>Unpin</code> and <code>Context</code> first.</p>
<h3 id="the-unpin-auto-trait"><a class="header" href="#the-unpin-auto-trait">The <code>Unpin</code> auto trait</a></h3>
<p>The type with <code>Unpin</code> auto trait implemented will cancel the effect of <code>Pin</code>, e.g. <code>Pin&lt;Box&lt;T&gt;&gt;</code> is as same as <code>Box&lt;T&gt;</code> when <code>T: Unpin</code>.
The reason is that these types doesn't depend on its location to work properly. The only exception is those types who implements <code>!Unpin</code>.</p>
<p>There are only 4 kinds of types that implements <code>!Unpin</code>:</p>
<ol>
<li><code>Future</code> generated by the compiler with the <code>async fn</code> syntax.</li>
<li><code>PhantomPinned</code> marker type.</li>
<li>Structs that contains <code>!Unpin</code> type in its field.</li>
<li><code>unsafe impl !Unpin for [what ever type here]</code></li>
</ol>
<p>The reason of why the compiler generated <code>Future</code> will be discussed in the next section. Now let's focus on <code>Context</code> first.</p>
<h2 id="2-contexta"><a class="header" href="#2-contexta">2. <code>Context&lt;'a&gt;</code></a></h2>
<p>This type defines the context of a async task. It's currently used to provide the access to a reference of a <code>Waker</code> that can wake
up the current task.</p>
<p>A <code>Waker</code> is essentially a wrapper to a vtable (<code>RawWakerVTable</code>) and some extra payloads (<code>data</code> pointer). The vtable contains:</p>
<ol>
<li><code>clone</code>: Function to run when the waker is cloned.</li>
<li><code>wake</code>: Function to run when <code>Waker::wake</code> is called. It will consume the <code>data</code> pointer.</li>
<li><code>wake_by_ref</code>: Function to run when <code>Waker::wake_by_ref</code> is called. It won't consume the <code>data</code> pointer.</li>
<li><code>drop</code>: Function to run when the <code>Waker</code> is dropped.</li>
</ol>
<p>Typically, the creation of a <code>Waker</code> is done by some other libraries (e.g. <code>waker_fn</code> for my implementation).
The <code>Waker</code>s' management will be discussed in <a href="layer/fst/../fth/waker_handling.html">Waker handling</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="future-desugar---a-finite-state-machine"><a class="header" href="#future-desugar---a-finite-state-machine">Future desugar - a Finite State Machine</a></h1>
<p>In Rust, we can create an async function as simple as the following code:</p>
<pre><code class="language-rust">async fn async_func() {
    init_step();
    f().await;
    g().await;
    h().await;
    final_step();
}
</code></pre>
<p>From a user's perspective, we can quickly conclude that the function will run
<code>f()</code>, <code>g()</code>, <code>h()</code> in order asynchrnously. But how this snippet is related
to the <code>Future</code> trait? It turns out that the compiler will translate the code snippet
into the following:</p>
<pre><code class="language-rust">struct AsyncFunc {
    fut_f: FutF,
    fut_g: FutG,
    fut_h: FutH,
    state: AsyncFuncState,
}

enum AsyncFuncState {
    Init,
    AwaitF,
    AwaitG,
    AwaitH,
    Final,
}

impl Future for AsyncFunc {
    type Output = ();

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {
        let me = self.get_mut();
        loop {
            match me.state {
                AsyncFuncState::Init =&gt; {
                    init_step();
                    me.state = AsyncFuncState::AwaitF;
                },
                AsyncFuncState::AwaitF =&gt; match me.fut_f.poll(cx) {
                    Poll::Ready(()) =&gt; me.state = AsyncFuncState::AwaitG,
                    Poll::Pending =&gt; break Poll::Pending,
                },
                AsyncFuncState::AwaitG =&gt; match me.fut_g.poll(cx) {
                    Poll::Ready(()) =&gt; me.state = AsyncFuncState::AwaitH,
                    Poll::Pending =&gt; break Poll::Pending,
                },
                AsyncFuncState::AwaitH =&gt; match me.fut_h.poll(cx) {
                    Poll::Ready(()) =&gt; me.state = AsyncFuncState::Final,
                    Poll::Pending =&gt; break Poll::Pending,
                },
                AsyncFuncState::Final =&gt; {
                    final_step();
                    break Poll::Ready(());
                },
            }
        }
    }
}
</code></pre>
<p>This code can be viewed as an finite state machine, and can be visualized as the following diagram:
<img src="https://i2.lensdump.com/i/RkBbkv.png" alt="" /></p>
<p>Since the code is compiled to a finite state machine, the state can store the arguments for the future to run,
the return value of previous future execution, etc. Because of this, the use of <code>Pin</code> and <code>!Unpin</code> is necessary.</p>
<h2 id="why-use-pin-and-why-the-generated-code-implements-unpin"><a class="header" href="#why-use-pin-and-why-the-generated-code-implements-unpin">Why use <code>Pin</code> and why the generated code implements <code>!Unpin</code>?</a></h2>
<p>Consider the following async block:</p>
<pre><code class="language-rust">async {
    let mut x = [0u8; 4096];
    let fut = read_to_buf(&amp;mut x);
    let n = fut.await;
    println!(&quot;got {:?}&quot;, &amp;x[..n]);
}
</code></pre>
<p>The compiler will generate the following structure:</p>
<pre><code class="language-rust">struct ReadToBuf&lt;'a&gt; {
    buf: &amp;'a mut [u8],
}
struct AsyncBlock1 {
    x: [u8; 4096],
    fut: ReadToBuf&lt;'_&gt;, // self refer to x field
    state: State,
}
</code></pre>
<p>We can see that the generated <code>AsyncBlock1</code> contains a future <code>ReadToBuf&lt;'_&gt;</code> that uses <code>&amp;mut x</code> for reading.
If this async block is moved, so will <code>x</code>, and since <code>x</code> is moved, the pointer in <code>ReadToBuf&lt;'_&gt;</code> can point
to an invalid location or dangle, causing undefined behavior. To prevent this, the generated <code>Future</code> object
will always be <code>!Unpin</code> to enable the effect that <code>Pin</code> brings, and thus the <code>poll</code> function takes
<code>self: Pin&lt;&amp;mut Self&gt;</code> rather than <code>&amp;mut self</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-challenge-of-managing-future-objects"><a class="header" href="#the-challenge-of-managing-future-objects">The challenge of managing Future objects</a></h1>
<p>With the previous sections, we can know that:</p>
<ol>
<li><code>Future</code> object is lazy.</li>
<li><code>Future</code> object needs a <code>Context</code>, which is obtained by a <code>Waker</code>, to be polled.</li>
<li>Generated <code>Future</code> object can contain numbers of anonymous states and fields.</li>
<li>Generated <code>Future</code> object is always <code>!Unpin</code>.</li>
</ol>
<p>Managing the generated <code>Future</code> objects is quite a hurdle, as it's impossible to type
any <code>Future</code> statically so that all the generated <code>Future</code> objects runs on stack,
and it's quite inefficient to actively poll every <code>Future</code> object you get with a
empty <code>Waker</code> (basically busy waiting).</p>
<p>In the next section, I will discuss how to manage these generated bastards using heap.
While it's not zero-cost, managing the generated <code>Futures</code> as heap-allocated trait objects
is much simpler tahn fighting with the borrowchecker and the moving problems caused by <code>!Unpin</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generic-future-handling"><a class="header" href="#generic-future-handling">Generic Future handling</a></h1>
<p>In this part, we will:</p>
<ul>
<li>Dicuss how to handle generic <code>Future</code> objects.</li>
<li>Talk about my approach to solve this problem.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-heap-allocated-future-object"><a class="header" href="#general-heap-allocated-future-object">General heap-allocated Future object</a></h1>
<p>Rust has the following ways to handle generic objects:</p>
<ol>
<li>By <code>&lt;T: Trait + 'lifetime&gt;</code>: Specifies a type parameter with trait bound and lifetime bound.</li>
<li>By <code>impl Trait</code>: Use an anonymous type parameter bound by trait.</li>
<li>By <code>dyn Trait</code>: Use an trait object to dynamic dispatch type.</li>
</ol>
<p>Method 1 needs to know the exactly type in compile time, and method 2 can be only used at function signature,
our only option is by method 3, trait objects.</p>
<p>Since a trait object is an opaque type that the size is only known at runtime,
we need to use a pointer to access it.
As storing on stack needs to play with lots of lifetime bounds, w only consider these heap-allocated pointer types:</p>
<ul>
<li><code>Pin&lt;Box&lt;dyn Future + AutoTraits + 'a&gt;&gt;</code></li>
<li><code>Pin&lt;Rc&lt;dyn Future + AutoTraits + 'a&gt;&gt;</code></li>
<li><code>Pin&lt;Arc&lt;dyn Future + AutoTraits + 'a&gt;&gt;</code></li>
</ul>
<p>A natural choice will be the <code>Box</code> one, since we only need to put it on heap.
You might think that doesn't <code>Future</code>'s <code>poll</code> function require <code>Pin&lt;&amp;mut Self&gt;</code>? We don't need internal mutability inside?
As it turns out, we can make use of <code>AsMut</code> trait, that using <code>.as_mut()</code> will result in:</p>
<pre><code>&amp;mut Pin&lt;P&lt;T&gt;&gt; -&gt; Pin&lt;&amp;mut T&gt;
</code></pre>
<p>We only need the internal mutability stuff out side:</p>
<pre><code class="language-rust">RefCell&lt;Pin&lt;Box&lt;dyn Future + 'a&gt;&gt;&gt; // Single thread.
Mutex&lt;Pin&lt;Box&lt;dyn Future + 'a&gt;&gt;&gt; // Multi thread.
</code></pre>
<p>These internal mutability needs a reference counted pointers to access properly, so we need to wrap it with <code>Rc</code> or <code>Arc</code>:</p>
<pre><code class="language-rust">Rc&lt;RefCell&lt;Pin&lt;Box&lt;dyn Future + 'a&gt;&gt;&gt;&gt; // Single thread.
Arc&lt;Mutex&lt;Pin&lt;Box&lt;dyn Future + 'a&gt;&gt;&gt;&gt; // Multi thread.
</code></pre>
<p>or:</p>
<pre><code class="language-rust">Pin&lt;Rc&lt;RefCell&lt;dyn Future + 'a&gt;&gt;&gt; // Single thread.
Pin&lt;Arc&lt;Mutex&lt;dyn Future + 'a&gt;&gt;&gt; // Multi thread.
</code></pre>
<p>with newer stable version of Rust as <code>Rc</code> and <code>Arc</code> also put stuff on heap (Note that <code>Pin</code> can only contain a pointer type).</p>
<p>At this point, you are good to go, although there may be a problem.
You see, you need to allocate every time a <code>Future</code> is spawned in your runtime. For an server type program
that spawns multiple handler that may be inefficient:</p>
<ol>
<li><code>Future</code> objects are allocated and destoryed multiple times, which can cause fragmentation depending on the global allocator.</li>
<li>The allocated space can actually be reused to reduce heap size and have a better performance as no allocation occurred when we reuse it.</li>
</ol>
<p>That's why I change to use a global object pool provided by <code>sharded_slab</code>.
The next section I will talk about how to use a global object pool to handle <code>Future</code> objects.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="global-reusable-object-pool-for-allocation-reuse-fragment-control-and-easy-managment"><a class="header" href="#global-reusable-object-pool-for-allocation-reuse-fragment-control-and-easy-managment">Global Reusable Object Pool for allocation reuse, fragment control, and easy managment</a></h1>
<p><code>sharded_slab</code> provides <code>Pool</code> for object pool that can:</p>
<ol>
<li>Allocate inside the pool.</li>
<li>Retain the allocation inside the pool when an entry is cleared.</li>
<li>Reuse the retained allocation when allocation occurs.</li>
</ol>
<p>The pool requires <code>T: Clear + Default</code>, that the <code>Clear</code> trait is used to clear value and retain allocation.
We can use this to design the type we want to store. In this case, the follwoing type is choosed:</p>
<pre><code class="language-rust">// type Boxed&lt;T&gt; = Pin&lt;Box&lt;dyn Future&lt;Output = T&gt; + Send + 'static&gt;&gt;;
pub(crate) struct BoxedFuture {
    pub(crate) future: Mutex&lt;Option&lt;Boxed&lt;io::Result&lt;()&gt;&gt;&gt;&gt;,
}
</code></pre>
<p>By default, <code>Option&lt;T&gt;</code> implements <code>Clear</code> by default, which uses <code>Option::take()</code> to do the clear job.
<code>Option::take()</code> itself is implmented by <code>std::mem::replace(self, None)</code>, which the <code>std::mem::replace</code>
won't dealloc the left hand side. This property makes it capable to do the allocation retain job, so we can
put the <code>Boxed</code> type under it. The <code>Mutex</code> wraps around it is to provide internal mutability for <code>Future</code>'s <code>poll</code> requirement.</p>
<p>We can implement <code>Clear</code> for <code>BoxedFuture</code> with <code>Option::clear()</code>:</p>
<pre><code class="language-rust">impl Default for BoxedFuture {
    fn default() -&gt; Self {
        BoxedFuture {
            future: Mutex::new(None),
        }
    }
}

impl Clear for BoxedFuture {
    fn clear(&amp;mut self) {
        self.future.get_mut().clear();
    }
}
</code></pre>
<p>Then create a global future object pool with <code>Lazy</code> from <code>once_cell</code>:</p>
<pre><code class="language-rust">// global future allocation pool.
pub(crate) static FUTURE_POOL: Lazy&lt;Pool&lt;BoxedFuture&gt;&gt; = Lazy::new(Pool::new);
</code></pre>
<p>The key will be wrpped inside <code>FutureIndex</code> that contains other payloads:</p>
<pre><code class="language-rust">#[derive(Clone, Copy, Eq)]
pub struct FutureIndex {
    pub key: usize,
    // Other payloads...
}

impl PartialEq for FutureIndex {
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        self.key == other.key
    }
}

impl Hash for FutureIndex {
    fn hash&lt;H: std::hash::Hasher&gt;(&amp;self, state: &amp;mut H) {
        self.key.hash(state);
    }
}
</code></pre>
<h2 id="the-overall-step-of-future-processing"><a class="header" href="#the-overall-step-of-future-processing">The overall step of <code>Future</code> processing</a></h2>
<ol>
<li>Allocate future object inside the pool when a future is spawned. The pool will return a key to access the entry where the future is.
<pre><code class="language-rust">// in Spawner::spawn_with_handle()
// ...
let key = FUTURE_POOL
    .create_with(|seat| {
        seat.future.get_mut().replace(spawn_fut.boxed());
    })
    .unwrap();
// ...
</code></pre>
</li>
<li>The key is used instead of a pointer to be processed by the message system and the schedule system.
<pre><code class="language-rust">// in Spawner::spawn_with_handle(), after step 1
// ...
self.tx
    .send(ScheduleMessage::Schedule(FutureIndex {
        key,
        // Other payloads...
    }))
    .expect(&quot;Failed to send message&quot;);
// ...
</code></pre>
</li>
<li>When the future is going to be processed:
<ol>
<li>The worker will use the key to gain the access of the future in pool.
<pre><code class="language-rust">// in scheduler::process_future()
if let Some(boxed) = FUTURE_POOL.get(index.key) {
    let finished = boxed.run(&amp;index, tx.clone());
} // ...
</code></pre>
</li>
<li>Lock the future and gain <code>&amp;mut</code> to use <code>Future::poll</code> and poll the future. Return if the future is <code>Ready</code>.
<pre><code class="language-rust">// in BoxedFuture::run()
let mut guard = self.future.lock();
// run *ONCE*
if let Some(fut) = guard.as_mut() {
    let waker = waker_fn(move || {
        // Create waker
    });
    let cx = &amp;mut Context::from_waker(&amp;waker);
    match fut.as_mut().poll(cx) {
        Poll::Ready(r) =&gt; {
            if let Err(e) = r {
                // log error
            }
            true
        }
        Poll::Pending =&gt; false,
    }
} else {
    true
}
</code></pre>
</li>
</ol>
</li>
<li>If the future is <code>Poll::Ready</code>, clear the future for future allocation reuse.
<pre><code class="language-rust">// in scheduler::process_future()
if finished {
    // ...
    if !FUTURE_POOL.clear(index.key) {
        // ...
    }
}
</code></pre>
</li>
</ol>
<h2 id="note"><a class="header" href="#note">Note</a></h2>
<p>The <code>Future</code> object is now single accessed by a single thread, why use <code>Mutex</code> instead of <code>RefCell</code> as they both implement <code>Send</code>?
This is because that the pool itself needs <code>Sync</code> for the global pool encapsulate in <code>Lazy</code> to wrok properly in multi-threaded environment.
We need to use <code>Mutex</code> to make the type store inside the pool <code>Sync</code>.</p>
<p>The <code>Mutex</code> will have small impact since it's already single accessed, its function will be like a <code>RefCell</code> that the thread-blocking function is canceled by our design.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="io-adapter-for-general-file-descriptor---iowrapper"><a class="header" href="#io-adapter-for-general-file-descriptor---iowrapper">IO Adapter for general file descriptor - IoWrapper</a></h1>
<p>Other than <code>Future</code> object handling, we also need IO source to make
<code>async</code> a thing as IO is the reason why we need asynchronous runtime.</p>
<p>In this section, we will talk about:</p>
<ol>
<li>General IO handling</li>
<li><code>IoWrapper</code> design</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-io-handling"><a class="header" href="#general-io-handling">General IO handling</a></h1>
<p>Generally, when using asynchronous runtime in Rust, you're dealing with non-blocking IO,
you'll want to make the file descriptors you're working on.</p>
<p>Setting a file descriptor is easy by using <code>fcntl</code> to set the <code>O_NONBLOCK</code>.</p>
<p>Next we'll talk about the error handling part.</p>
<p>A non-blocking IO handling can be described by the following pseudo code:</p>
<pre><code>run_nbio(io):
    n &lt;- io()
    if n == -1 then
        if (errno == EWOULDBLOCK) then
            // The io action will block, try again later
            return PENDING, nil
        else if (errno == EINTERRUPT) then
            // The action is interrupted by system, retry immediately
            return nbio()
        else
            // io is completed with error
            // other errors are handled by the user
            return READY, -1
        end
    else
        // io is completed
        return READY, n
    end
</code></pre>
<p>Basically the code will only handle two kinds of error itself: <code>EWOULDBLOCK</code> and <code>EINTERRUPT</code>:</p>
<ol>
<li><code>EWOULDBLOCK</code> means that <code>io()</code> will block the thread, return <code>PENDING</code> to make the user try again later.</li>
<li><code>EINTERRUPT</code> means that an interrupt occurs when running <code>io()</code>, retry immediately.</li>
</ol>
<p>We can then bring this to Rust:</p>
<pre><code class="language-rust">// in IoWrapper::poll_ref()
fn poll_ref&lt;U, F&gt;(
    &amp;self,
    cx: &amp;mut Context&lt;'_&gt;, // context for polling
    interest: Interest, // READ or WRITE
    mut f: F, // action
) -&gt; Poll&lt;io::Result&lt;U&gt;&gt;
where
    F: FnMut(&amp;Self) -&gt; io::Result&lt;U&gt;,
{
    match f(self) {
        // WouldBlock, do it when the io is available.
        Err(ref e) if e.kind() == io::ErrorKind::WouldBlock =&gt; {
            let current = self.token.load(Ordering::Relaxed);
            // Register to the reactor.
            // The reactor will wake the task to run this again
            // when it gets the event correspoding to the interst.
            self.register_reactor(current, interest, cx)?;
            Poll::Pending
        }
        // Interrupt, retry immediately
        Err(ref e) if e.kind() == io::ErrorKind::Interrupted =&gt; self.poll_ref(cx, interest, f),
        // Ready with Success or other Error
        r =&gt; Poll::Ready(r),
    }
}
</code></pre>
<p>Next, we'll talk about <code>IoWrapper</code>'s design.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iowrapper-design"><a class="header" href="#iowrapper-design">IoWrapper design</a></h1>
<p><code>IoWrapper</code> is a wrapper for IO sources like <code>File</code>, <code>TcpStream</code>, etc. to become an IO event provider
for the runtime. The wrapper provides varius defaults and methods for users to define a new IO source quickly.</p>
<p>The <code>IoWrapper</code> is defined as:</p>
<pre><code class="language-rust">pub struct IoWrapper&lt;T: AsFd&gt; {
    inner: T,
    token: AtomicUsize,
}
</code></pre>
<p>where <code>inner</code> is the type being wrapped, and <code>token</code> is the token that can identify the struct.</p>
<p>The wrapped type is bounded by <code>AsFd</code> since the runtime only accecpts registering IO events related
to system IO, the wrapper thus requires the types to be wrapped should be <code>AsFd</code> that can extracxt
the underlying file descripter.</p>
<p><code>IoWrapper</code> provides:</p>
<ul>
<li>A convenient wrapper over <code>AsFd</code> types that set to non-blocking mode automatically.</li>
<li><code>ref_io</code> and <code>mut_io</code> for IO that doesn't require/require mutating self.
<ul>
<li><code>ref_io</code> and <code>mut_io</code> are also async function by themselves, you don't need to implement <code>Future</code> yourself.</li>
<li>You can use these function to perform IO operations that aren't defined by the runtime or other async traits.</li>
<li>For usage, see <a href="https://smb374.github.io/my-async-rs/api_references/my_async/struct.IoWrapper.html">API documentation</a></li>
</ul>
</li>
<li>Auto implementation of <code>AsyncRead</code> and <code>AsyncWrite</code> for types implementing <code>std::io::Read</code> and <code>std::io::Write</code>.</li>
<li>Get reference/mutable reference of the inner type by <code>IoWrapper::inner()</code>/<code>IoWrapper::inner_mut()</code>.</li>
</ul>
<p>In addition to these features, since an <code>IoWrapper</code> wraps over any <code>AsFd</code> type with a token, we can register it with the token
to the reactor of the runtime. The reactor will then look after its events, and thus can wake up tasks related to it corresponding
to <code>Interest::READABLE</code> or <code>Interest::WRITABLE</code>. In this way, <code>IoWrapper</code> can play the role of IO events provider
to wake async tasks. The rest of the details will be discussed in the subsections of <a href="layer/fst/layer/fth/reactor.html">System IO Event Harvester - Reactor</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="heart-of-a-runtime---executor"><a class="header" href="#heart-of-a-runtime---executor">Heart of a runtime - Executor</a></h1>
<p>In the previous section, we've described:</p>
<ol>
<li>How to prperly handle compiler generated <code>Future</code> objects</li>
<li><code>IoWrapper</code> that is capable of being an IO source that provides IO events for waking tasks.</li>
</ol>
<p>But defineing these won't fire up the execution procedure, we still need an executor to process these
tasks. In this section, we'll discuss:</p>
<ol>
<li><code>Executor</code> for executing <code>Future</code>s.
<ul>
<li>General commands of a runtime.</li>
<li><code>Executor</code>'s design.</li>
</ul>
</li>
<li>Passing messages.
<ul>
<li><code>Spawner</code> - a message sender.</li>
<li>Message payload.</li>
</ul>
</li>
<li><code>JoinHandle</code> for spawned future.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-commands-of-a-runtime"><a class="header" href="#general-commands-of-a-runtime">General commands of a runtime</a></h1>
<p>Imagine you're user that holds a pool of <code>Future</code> objects that is ready to execute, and the <code>Executor</code>
as a server that is capable to execute your <code>Future</code> objects with their results return to you.</p>
<p>Naturally, you'll want to send a request that asks the server to execute your task. You can, of course, choose
to wait until the server finishes the task and retrieves its result, or you can choose to tell the server: Give
me a handle and I'll check its status later. Let's call the latter one <code>spawn</code>.</p>
<p>We can show the differences with the following snippet:</p>
<pre><code class="language-rust">// Wait until `f()` finishes and retrieve its result.
async fn af1() {
    let result = f().await;
    // Do the rest of stuff...
}
async fn af2() {
    let handle = spawn(f());
    // Do other stuff...
    // Check the result of execution.
    let result = handle.join().await;
}
</code></pre>
<p>As you can see, we need to define a <code>spawn</code> function to handle these kind of requests.
Note that in the first case, no extra <code>Future</code> object is created as it will become a state of the <code>Future</code>
object generated by <code>af1()</code>'s code, so we don't need a command to handle it.</p>
<p>Now, let's say that you're done with the works, and you want to shutdown the server. Naturally,
you'll call the <code>shutdown</code> command to close the server before exit.</p>
<p>By the above situation, we can see that we need two essential commands: <code>spawn()</code> and <code>shutdown()</code> to control
the <code>Executor</code> we need to use. Of course there can be more commands, but for <code>my-async</code>, these commands are enough.
Now, let's talk about how we can design the <code>Executor</code> we need with the requirements.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-of-executor"><a class="header" href="#design-of-executor">Design of Executor</a></h1>
<p>By the previous section, we can now create a pseudocode to illustrate the command handling:</p>
<pre><code>HandleRequests():
    while true:
        r &lt;- GetRequest()
        match r:
            Spawn(Task) -&gt; Put the Task to the execution system
            Shutdown -&gt; break
</code></pre>
<p>The execution system is done by the <code>Scheduler</code>, and we also need to call <code>Reactor</code> to look up for
IO events to wake tasks. By these facts and the above pseudo code, the <code>Executor</code> can be viewed
as an abstraction layer that handles messages and relay the actual actions to <code>Scheduler</code> and <code>Reactor</code>.</p>
<p>In the code, the <code>Executor</code> will do almost the same thing with one more message to handle. The <code>Executor</code>
will also spawn a thread for <code>Reactor</code> to run, as the IO events will need to be checked separately if
we have the message handling loop in the main thread.</p>
<p>The <code>Executor</code> also provides a function: <code>block_on</code>. The async function that's spawned by the <code>block_on</code> function
is just like the <code>main</code> function in a normal program: the runtime won't exit before this function ends without
furthur errors or interrupts occur during runtime.</p>
<p>The complete pseudocode for the <code>Executor</code>:</p>
<pre><code>Init():
    Initialize the Scheduler.
    Spawn a thread to init and run the Reactor.
    Set error hook for graceful shutdown to clean storages.
    Return instance of self

HandleRequests():
    while true:
        r &lt;- GetRequest()
        match r:
            Spawn(Task) -&gt; Put the Task to the execution system
            Shutdown -&gt; break

Run():
    HandleRequests()
    Send Shutdown message to the Reactor
    Join the thread for the Reactor

block_on(f):
    handle &lt;- spawn(f())
    Run()
    Get the result from handle
    Return result of f()
</code></pre>
<p>Next, we'll talk about the message passing in this design.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="passing-messages"><a class="header" href="#passing-messages">Passing messages</a></h1>
<p>According to the previous section, we have two commands to handle:</p>
<ol>
<li>spawn</li>
<li>shutdown</li>
</ol>
<p>The corresponding messages is defined:</p>
<pre><code class="language-rust">// in src/schedulers/mod.rs:
pub enum ScheduleMessage {
    Schedule(FutureIndex),
    Reschedule(FutureIndex),
    Shutdown,
}
</code></pre>
<p>where <code>Schedule</code> is to handle spawn, and <code>Shutdown</code> is to handle shutdown.</p>
<p>The <code>Reschedule</code> message is an internal message that is used to requeue a task, usually used when
a worker's queue is full that the worker can put excessive tasks back to global queue for others to taks.
For more details, see <a href="layer/snd/layer/trd/schedule_procedure.html">The procedure of task scheduling</a>.</p>
<p>With the message defined, we can code the message handle loop of <code>Executor</code>:</p>
<pre><code class="language-rust">// Executor::run() code
fn run(mut self) {
    loop {
        // The sender half will send message.
        match self.scheduler.receiver().recv() { // Blocking receive
            Ok(msg) =&gt; match msg {
                ScheduleMessage::Schedule(future) =&gt; // Scheduler schedule future,
                ScheduleMessage::Reschedule(task) =&gt; // Scheduler reschedule task,
                ScheduleMessage::Shutdown =&gt; break,
            },
            Err(_) =&gt; { // sender disconnected
                log::debug!(&quot;exit...&quot;);
                break;
            }
        }
    }
    // Shutdown procedures...
}
</code></pre>
<p>The <code>Executor</code> will receive messages until:</p>
<ol>
<li>Sender half of the channel is diconnected.</li>
<li>Got <code>ScheduleMessage::Shutdown</code>.</li>
</ol>
<p>In the subsections, we'll look at:</p>
<ol>
<li>The sender half.</li>
<li>The message payload.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spawner---message-sender"><a class="header" href="#spawner---message-sender">Spawner - message sender</a></h1>
<p>The sender half is defined as <code>Spawner</code>, which contains the sender half of the message passing channel.
When the <code>Executor</code> initialize, it will also initialize a global <code>Spawner</code> for user to use <code>spawn()</code> and <code>shutdown()</code>.</p>
<p>When calling <code>spawn()</code> or <code>Executor::block_on()</code>, the <code>Spawner</code> will do the following stufff before
<code>ScheduleMessage::Schedule</code> is send:</p>
<ol>
<li>Create a shared memory for the future handle to use</li>
<li>Add extra code after the future need to spawned that
<ul>
<li>Put the execution result to the shared memory.</li>
<li>Check if it is called by <code>block_on</code>, if yes, shutdown the runtime.</li>
</ul>
</li>
<li>Allocate the <code>Future</code> in global <code>Future</code> object pool and get its key.</li>
<li>Construct the <code>FuturIndex</code> with the key and other payloads.</li>
<li>Send <code>ScheduleMessage::Schedule</code> with the <code>FutureIndex</code>.</li>
<li>Return the handle to the spawned future.</li>
</ol>
<p>The code:</p>
<pre><code class="language-rust">// Spawner::spawn_with_handle()
pub fn spawn_with_handle&lt;F&gt;(&amp;self, future: F, is_block: bool) -&gt; JoinHandle&lt;F::Output&gt;
where
    F: Future + Send + 'static,
    F::Output: Send + 'static,
{
    // Step 1.
    let result_arc: Arc&lt;Mutex&lt;Option&lt;F::Output&gt;&gt;&gt; = Arc::new(Mutex::new(None));
    // Step 2.
    let clone = result_arc.clone();
    let spawn_fut = async move {
        let output = future.await;
        // Store the result.
        let mut guard = clone.lock();
        guard.replace(output);
        // Check if the function is called by `Executor::block_on()`
        if is_block {
            log::info!(&quot;Shutting down...&quot;);
            shutdown();
        }
        Ok(())
    };
    // Step 3.
    let key = FUTURE_POOL
        .create_with(|seat| {
            seat.future.get_mut().replace(spawn_fut.boxed());
        })
        .unwrap();
    // Used in auto task yielding if enabled.
    let budget_index = BUDGET_SLAB
        .insert(AtomicUsize::new(DEFAULT_BUDGET))
        .unwrap();
    // Step 4., Step 5.
    self.tx
        .send(ScheduleMessage::Schedule(FutureIndex {
            key,
            budget_index,
            sleep_count: 0,
        }))
        .expect(&quot;Failed to send message&quot;);
    // Step 6.
    JoinHandle {
        spawn_id: key,
        registered: AtomicBool::new(false),
        inner: result_arc,
    }
}
</code></pre>
<p>For, <code>Shutdown</code> and <code>Reschedule</code>, the implementation is simple: simply send the corresponding message with necessary arguments.
We can also define <code>spawn()</code> and <code>shutdown()</code> now as their just a wrapper to call the global spawner and use its method call
to send messages to the <code>Executor</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="message-payload"><a class="header" href="#message-payload">Message payload</a></h1>
<p>The code in the previous section shows that the <code>FutureIndex</code> contains two extra payloads.
The two payloads are related to scheduling, that:</p>
<ol>
<li><code>sleep_count</code>: The sleep count is used in <code>HybridScheduler</code>, that it is used to prioritize the tasks. See <a href="layer/snd/layer/trd/hybrid.html">Hybrid Queue for Prioritized Work Stealing</a></li>
<li><code>budget_index</code>: Index for retrieving budgets, that is used for auto task yielding. See <a href="layer/snd/layer/trd/token_bucket.html">A token bucket like algorithm for auto task yielding</a></li>
</ol>
<p>Although the payloads is hard coded, when you design your own executor, you can store informations that is used for
runtime metrics.</p>
<p>For generic payloads, you can use a trait object to achieve, such as:</p>
<pre><code class="language-rust">trait GenericPayload {
    // methods and associated types in here
}

struct FutureIndex&lt;'a&gt; {
    key: usize,
    payload: Arc&lt;Mutex&lt;dyn GenericPayload + 'a&gt;&gt;, // for payload mutation
}
</code></pre>
<p>Next, we'll move onb to <code>JoinHandle</code>'s design.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="join-handle-for-future"><a class="header" href="#join-handle-for-future">Join Handle for Future</a></h1>
<p>As shown before, we use a shared memory to store the result of the spawned future, then we put the
shared memory into <code>JoinHandle</code> and return to the user.</p>
<p>The <code>JoinHandle</code> is defined as:</p>
<pre><code class="language-rust">pub struct JoinHandle&lt;T&gt; {
    spawn_id: usize,
    registered: AtomicBool,
    inner: Arc&lt;Mutex&lt;Option&lt;T&gt;&gt;&gt;,
}
</code></pre>
<p>where</p>
<ul>
<li><code>spawn_id</code> is the id of the spawned future.</li>
<li><code>registered</code> is a flag to check if the waker of it is registered.</li>
<li><code>inner</code> is the shared memory.</li>
</ul>
<p>We can take a look at <code>join()</code> and <code>try_join()</code> with other structs and functions to see how it works:</p>
<pre><code class="language-rust">static JOIN_HANDLE_MAP: Lazy&lt;RwLock&lt;FxHashMap&lt;usize, Waker&gt;&gt;&gt; =
    Lazy::new(|| RwLock::new(FxHashMap::default()));

pub struct FutureJoin&lt;'a, T&gt; {
    handle: &amp;'a JoinHandle&lt;T&gt;,
}

impl&lt;T&gt; JoinHandle&lt;T&gt; {
    pub fn join(&amp;self) -&gt; FutureJoin&lt;'_, T&gt; {
        FutureJoin { handle: self }
    }
    pub fn try_join(&amp;self) -&gt; Option&lt;T&gt; {
        let mut guard = self.inner.lock();
        guard.take()
    }
    fn register_waker(&amp;self, waker: Waker) {
        JOIN_HANDLE_MAP.write().insert(self.spawn_id, waker);
        self.registered.store(true, Ordering::Relaxed);
    }
    fn deregister_waker(&amp;self) {
        JOIN_HANDLE_MAP.write().remove(&amp;self.spawn_id);
        self.registered.store(false, Ordering::Relaxed);
    }
}

impl&lt;'a, T&gt; Future for FutureJoin&lt;'a, T&gt; {
    type Output = T;
    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {
        let me = self.handle;
        // Lock the shared memory and try to take the content of it.
        let mut guard = me.inner.lock();
        match guard.take() {
            // If success
            Some(val) =&gt; {
                // Deregister the waker from JOIN_HANDLE_MAP
                if me.registered.load(Ordering::Relaxed) {
                    me.deregister_waker();
                }
                // Return Ready(val)
                Poll::Ready(val)
            }
            // Else
            None =&gt; {
                // Register waker if the waker is not registered
                if !me.registered.load(Ordering::Relaxed) {
                    // spawned future can use it's own id to wake JoinHandle.
                    me.register_waker(cx.waker().clone());
                }
                // Return Pending
                Poll::Pending
            }
        }
    }
}

// Called when a spawned future finishes running
// If the waker is registered, we wake it up
// Otherwise, the JoinHandle hasn't request join.
pub(super) fn wake_join_handle(index: usize) {
    if let Some(waker) = JOIN_HANDLE_MAP.read().get(&amp;index) {
        waker.wake_by_ref();
    }
}
</code></pre>
<p>Since we use a shared memory that is <code>Arc&lt;Mutex&lt;Option&lt;T&gt;&gt;&gt;</code>, the <code>try_join()</code> can be implemented easily
by lock <code>inner</code> and take it. The <code>Option&lt;T&gt;</code>'s value can indicate the success or not.</p>
<p><code>join()</code> is a async function that will wait until the future of the handle finishes execution, that is,
if <code>inner</code> is <code>None</code>, we register the waker of the context where you call <code>join()</code> to a map.
The entry will use the spawned future's key (<code>spawn_id</code>) as its key so that the future can use the waker to wake
the context where <code>join()</code> is being called.</p>
<p>Take the following code as an example:</p>
<pre><code class="language-rust">async fn parent() {
    let handle = spawn(child());
    let result: T = handle.join().await; // waker is from parent's context
}

async fn child() -&gt; T {
    // do stuff...
    result
}
</code></pre>
<p><code>handle</code> will use the waker from context <code>cx</code> that is used to poll <code>parent</code>, while the waker registration uses
<code>child</code>'s index as its key so that <code>child</code> can wake <code>parent</code> to poll <code>handle.join()</code>.</p>
<p>Since we need to use the key of the spawned future as its key to the waker map, we can only use
a regular hashmap with a <code>RwLock</code> so that we can specify its key. This is the simplest way I've
tried so far, otherwise we need to make more complicated code so that we don't need to use a hashmap.</p>
<p>Anyways, that's all for the <code>Executor</code>, we'll now move one to the <code>Scheduler</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multithread-mania---scheduler"><a class="header" href="#multithread-mania---scheduler">Multithread mania - Scheduler</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scheduler-trait-design"><a class="header" href="#scheduler-trait-design">Scheduler trait design</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-worker-structure-and-logic"><a class="header" href="#general-worker-structure-and-logic">General Worker structure and logic</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-procedure-of-task-scheduling"><a class="header" href="#the-procedure-of-task-scheduling">The procedure of task scheduling</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="threading-method"><a class="header" href="#threading-method">Threading Method</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="round-robin"><a class="header" href="#round-robin">Round Robin</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="work-stealing"><a class="header" href="#work-stealing">Work Stealing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hybrid-queue-for-prioritized-work-stealing"><a class="header" href="#hybrid-queue-for-prioritized-work-stealing">Hybrid Queue for Prioritized Work Stealing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="a-token-bucket-like-algorithm-for-auto-task-yielding"><a class="header" href="#a-token-bucket-like-algorithm-for-auto-task-yielding">A token bucket like algorithm for auto task yielding</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="system-io-event-harvester---reactor"><a class="header" href="#system-io-event-harvester---reactor">System IO Event Harvester - Reactor</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="io-event-registeration"><a class="header" href="#io-event-registeration">IO event registeration</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="event-handling"><a class="header" href="#event-handling">Event handling</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="event-maintain-for-late-use"><a class="header" href="#event-maintain-for-late-use">Event maintain for late use</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="waker-handling"><a class="header" href="#waker-handling">Waker handling</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="global-slab-for-wakers"><a class="header" href="#global-slab-for-wakers">Global slab for wakers</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="waker-registration"><a class="header" href="#waker-registration">Waker registration</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="load-balancing"><a class="header" href="#load-balancing">Load Balancing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generic-message-payload"><a class="header" href="#generic-message-payload">Generic Message Payload</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reactor-abstraction-for-different-systems"><a class="header" href="#reactor-abstraction-for-different-systems">Reactor abstraction for different systems</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="references"><a class="header" href="#references">References</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </body>
</html>
